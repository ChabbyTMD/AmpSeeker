# The main entry point of your workflow.
# After configuring, running snakemake -n in a clone of this repository should successfully execute a dry-run of the workflow.
report: "report/workflow.rst"
import pandas as pd 
import numpy as np

configfile:"config/config.yaml"

metadata = pd.read_csv(config['metadata'], sep="\t")
samples = metadata['sampleID']
#present = pd.read_csv(config['present_samples'], sep="\t", header=None)

# We have to remove absent samples, or workflow will fail 
#samples = metadata[metadata['sampleID'].isin(present[0])]['sampleID']

# Split into two sample sets as bcftools merge cant take over 1020 files
# So we must do two rounds of merging
n_samples = len(metadata)
half = int(n_samples/2)
samples1 = metadata['sampleID'][:half]
samples2 = metadata['sampleID'][half:]
#samples = samples[~np.isin(samples, ["AgamDaoLSTM1_1375", "AgamDaoLSTM1_1378", "])]

rule all:
    input:
        # The first rule should define the default target files
        cov = expand("results/{ref}/coverage/{sample}.per-base.bed.gz", sample=samples, ref=config['ref']),
       # cov2 = expand("results/wholegenome/coverage/windowed/{sample}.regions.bed.gz", sample=samples),
        stats = expand("resources/{ref}/alignments/bamStats/{sample}.flagstat", sample=samples,ref=config['ref']),
        bams = expand("resources/{ref}/alignments/{sample}.bam", sample=samples, ref=config['ref']),
        vcf = expand("results/{ref}/vcfs/AgamDaoLSTM_merged.vcf", ref=config['ref']),
        trimmed = expand("resources/reads/trimmed/{sample}_{n}.fastq.gz", n=[1,2], sample=samples, ref=config['ref'])

include: "rules/qc.smk"
include: "rules/AlignmentVariantCalling.smk"
include: "rules/BgzipTabixMerge.smk"
