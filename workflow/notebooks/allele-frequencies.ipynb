{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3f429b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import allel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_vcf(vcf_path, metadata, depth_filter=None):\n",
    "    \"\"\"\n",
    "    Load VCF and filter poor-quality samples\n",
    "    \"\"\"\n",
    "      \n",
    "    # load vcf and get genotypes and positions\n",
    "    vcf = allel.read_vcf(vcf_path, fields='*')\n",
    "    samples = vcf['samples']\n",
    "    # keep only samples in qcpass metadata \n",
    "    sample_mask = np.isin(vcf['samples'], metadata.sampleID)\n",
    "    \n",
    "    # remove low quality samples \n",
    "    geno = allel.GenotypeArray(vcf['calldata/GT'])\n",
    "    geno = geno.compress(sample_mask, axis=1)\n",
    "    pos = vcf['variants/POS']\n",
    "    contig = vcf['variants/CHROM']\n",
    "    indel = vcf['variants/INDEL']\n",
    "    \n",
    "    # remove indels \n",
    "    geno = geno.compress(~indel, axis=0)\n",
    "    pos = pos[~indel]\n",
    "    contig = contig[~indel]\n",
    "    ref = vcf['variants/REF'][~indel]\n",
    "    alt = vcf['variants/ALT'][~indel]\n",
    "    ann = read_ANN_field(vcf_path)[~indel]\n",
    "    \n",
    "    # filter on depth\n",
    "    if depth_filter:\n",
    "        depth = vcf['variants/DP']\n",
    "        mask = depth > depth_filter\n",
    "        geno = geno.compress(mask, axis=0)\n",
    "        pos = pos[mask]\n",
    "        contig = contig[mask]\n",
    "        ref = ref[mask]\n",
    "        alt = alt[mask]\n",
    "        ann = ann[mask]\n",
    "    \n",
    "    return geno, pos, contig, samples[sample_mask], ref, alt, ann\n",
    "\n",
    "def read_ANN_field(vcf_file):\n",
    "    anns = []\n",
    "    with open(vcf_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue  # Skip header lines\n",
    "            fields = line.strip().split('\\t')\n",
    "            info_field = fields[7]\n",
    "            info_pairs = info_field.split(';')\n",
    "            ann_value = None\n",
    "            for pair in info_pairs:\n",
    "                if pair.startswith('ANN='):\n",
    "                    ann_value = pair.split('=')[1]\n",
    "                    break\n",
    "            anns.append(ann_value)\n",
    "\n",
    "    return np.array(anns)\n",
    "\n",
    "def vcf_to_snp_dataframe(vcf_path, metadata):\n",
    "\n",
    "    geno, pos, contig, samples, ref, alt, ann = load_vcf(vcf_path=vcf_path, metadata=metadata)\n",
    "    \n",
    "    # make dataframe of variant positions and merge with bed\n",
    "    snp_df = pd.DataFrame({'contig':contig, 'pos':pos, 'ref':ref, 'alt':[list(a[a != \"\"]) for a in alt], 'ann':ann})\n",
    "\n",
    "    snp_df = snp_df.explode('alt').reset_index().rename(columns={'index':'variant_index'})\n",
    "    snp_df = snp_df.assign(alt_index=snp_df.groupby('pos').cumcount() + 1) \n",
    "    snp_df = snp_df.assign(label=lambda x: x.pos.astype(str) + \" | \" +  x.alt.fillna('NA'))\n",
    "    snp_df.head(2)\n",
    "\n",
    "    # split and find correct annotation \n",
    "    df = snp_df.assign(ann=lambda x: x.ann.str.split(\",\"))\n",
    "    anns = []\n",
    "    for i, row in df.iterrows():\n",
    "        alt = row['alt']\n",
    "        if row['ann'] == None:\n",
    "            ann = \"\"\n",
    "        else:\n",
    "            # keep only RD Vgsc annotations\n",
    "            if 'AGAP004707' in ','.join(row['ann']):\n",
    "                row['ann'] = [a for a in row['ann'] if \"AGAP004707-RD\" in a]\n",
    "\n",
    "            ann = ','.join([a for a in row['ann'] if a.startswith(alt)])\n",
    "        anns.append(ann)\n",
    "\n",
    "    snp_df = snp_df.assign(ann=anns)\n",
    "    \n",
    "    return snp_df, geno\n",
    "\n",
    "def calculate_frequencies_cohort(snp_df, metadata, geno, cohort_col, af_filter, missense_filter):\n",
    "    np.seterr(all=\"ignore\")\n",
    "    \n",
    "    df = snp_df.copy()\n",
    "    \n",
    "    # get indices of each cohort\n",
    "    coh_dict = {}\n",
    "    cohs = metadata[cohort_col].unique()\n",
    "    cohs = cohs[~pd.isnull(cohs)]\n",
    "    for coh in cohs:\n",
    "        coh_dict[coh] = np.where(metadata[cohort_col] == coh)[0]\n",
    "    \n",
    "    # get allele counts for each population\n",
    "    ac = geno.count_alleles_subpops(coh_dict, max_allele=3)\n",
    "    \n",
    "    for coh in cohs:\n",
    "        total_counts = []\n",
    "        alt_counts = []\n",
    "        for i, row in df.iterrows():\n",
    "            var_idx = row['variant_index']\n",
    "            alt_idx = row['alt_index']\n",
    "            total_counts.append(ac[coh][var_idx,:].sum())\n",
    "            alt_counts.append(ac[coh][var_idx, alt_idx])\n",
    "\n",
    "        df.loc[:, f'count_{coh}'] = np.array(alt_counts)\n",
    "        df.loc[:, f'frq_{coh}'] = np.round(np.array(alt_counts)/np.array(total_counts), 3)\n",
    "    \n",
    "    freq_df = df.set_index('label').filter(like='frq')\n",
    "    \n",
    "    ann_df = snp_df.ann.str.split(\"|\", expand=True).iloc[:, :11].drop(columns=[0,7,8])\n",
    "    ann_df.columns = ['type', 'effect', 'gene', 'geneID', 'modifier', 'transcript', 'base_change', 'aa_change']\n",
    "    snp_df = pd.concat([snp_df[['contig', 'pos', 'ref', 'alt']], ann_df], axis=1)\n",
    "    snp_freq_df = pd.concat([snp_df, freq_df.reset_index()], axis=1)\n",
    "\n",
    "    snp_freq_df = snp_freq_df.assign(label=\n",
    "                  lambda x: x.contig + \" | \" + x.geneID + \" | \" + x.pos.astype(str) + \" | \" + x.aa_change.str.replace(\"p.\", \"\") + \" | \" + x.alt.fillna(\" \")\n",
    "                 )\n",
    "    \n",
    "    if af_filter:\n",
    "        af_pass = (snp_freq_df.filter(like='frq') > 0.05).any(axis=1)\n",
    "        snp_freq_df = snp_freq_df[af_pass]\n",
    "    \n",
    "    if missense_filter:\n",
    "        snp_freq_df = snp_freq_df.query(\"type == 'missense_variant'\")\n",
    "    \n",
    "    return snp_freq_df.set_index('label')\n",
    "\n",
    "def plot_allele_frequencies(df, cohort_col):\n",
    "        \n",
    "    fig = px.imshow(\n",
    "            img=df,\n",
    "            zmin=0,\n",
    "            zmax=1,\n",
    "            width=np.max([800, df.shape[1] * 100]),\n",
    "            height=df.shape[0] * 20,\n",
    "            text_auto=True,\n",
    "            aspect=1,\n",
    "            color_continuous_scale=\"Reds\",\n",
    "            title=f\"Allele frequencies | by {cohort_col}\",\n",
    "        template='simple_white'\n",
    "        )\n",
    "    fig.update(layout_coloraxis_showscale=False)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4571035",
   "metadata": {
    "tags": [
     "remove-input",
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = 'ampseq-colony'\n",
    "metadata_path = \"../../results/config/metadata.qcpass.tsv\"\n",
    "cohort_cols = 'strain' #taxon,location'\n",
    "bed_path = \"../../config/ag-vampir.bed\"\n",
    "vcf_path = \"../../results/vcfs/targets/ampseq-colony.annot.vcf\"\n",
    "wkdir = \"../..\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d349d15",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "### Plotting allele frequencies\n",
    "\n",
    "This page shows allele frequencies in each cohort of the SNPs genotyped in the amplicon sequencing protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee8c132c",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "cohort_cols = cohort_cols.split(\",\")\n",
    "\n",
    "bed_df = pd.read_csv(bed_path, sep=\"\\t\", header=None, names=['contig', 'start', 'end', 'ref', 'alt', 'amplicon_id', 'mutation'])\n",
    "\n",
    "# load metadata\n",
    "if metadata_path.endswith('.xlsx'):\n",
    "    metadata = pd.read_excel(metadata_path, engine='openpyxl')\n",
    "elif metadata_path.endswith('.tsv'):\n",
    "    metadata = pd.read_csv(metadata_path, sep=\"\\t\")\n",
    "elif metadata_path.endswith('.csv'):\n",
    "    metadata = pd.read_csv(metadata_path, sep=\",\")\n",
    "else:\n",
    "    raise ValueError(\"Metadata file must be .xlsx or .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a63cb1",
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "snp_df, geno = vcf_to_snp_dataframe(vcf_path, metadata)\n",
    "\n",
    "frq_dfs = []\n",
    "for cohort_col in cohort_cols:\n",
    "    \n",
    "    freq_df = calculate_frequencies_cohort(\n",
    "        snp_df=snp_df, \n",
    "        metadata=metadata,\n",
    "        geno=geno, \n",
    "        cohort_col=cohort_col,\n",
    "        af_filter=None,\n",
    "        missense_filter=False\n",
    "    )\n",
    "    frq_dfs.append(freq_df.reset_index(drop=True))\n",
    "\n",
    "    plot_allele_frequencies(\n",
    "        df=freq_df.filter(like='frq_'),\n",
    "        cohort_col=cohort_col\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece08d55",
   "metadata": {},
   "source": [
    "#### SNP frequency summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ffa152",
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "snp_df = pd.concat([snp_df] + frq_dfs, axis=1)\n",
    "snp_df.to_csv(f\"{wkdir}/results/snp_frequencies_summary.tsv\", sep=\"\\t\")\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3267a7d",
   "metadata": {},
   "source": [
    "#### Allele frequencies of any SNPs across amplicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350de0cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vcf_path = f\"{wkdir}/results/vcfs/amplicons/{dataset}.annot.vcf\"\n",
    "cohort_col = cohort_cols[0]\n",
    "\n",
    "snp_df, geno = vcf_to_snp_dataframe(vcf_path, metadata)\n",
    "\n",
    "snp_freq_df = calculate_frequencies_cohort(\n",
    "    snp_df=snp_df, \n",
    "    metadata=metadata,\n",
    "    geno=geno, \n",
    "    cohort_col=cohort_col, \n",
    "    af_filter=0.05,\n",
    "    missense_filter=True\n",
    ")   \n",
    "\n",
    "snp_freq_df = snp_freq_df.filter(like='frq')\n",
    "snp_freq_df.columns = snp_freq_df.columns.str.replace(\"frq_\", \"\")\n",
    "\n",
    "plot_allele_frequencies(\n",
    "    df=snp_freq_df,\n",
    "    cohort_col=cohort_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87cff95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
