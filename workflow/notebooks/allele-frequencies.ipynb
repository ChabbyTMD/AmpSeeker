{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3f429b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import allel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_vcf(vcf_path, metadata, depth_filter=None):\n",
    "    \"\"\"\n",
    "    Load VCF and filter poor-quality samples\n",
    "    \"\"\"\n",
    "      \n",
    "    # load vcf and get genotypes and positions\n",
    "    vcf = allel.read_vcf(vcf_path, fields='*')\n",
    "    samples = vcf['samples']\n",
    "    # keep only samples in qcpass metadata \n",
    "    sample_mask = np.isin(vcf['samples'], metadata.sample_id)\n",
    "    \n",
    "    # remove low quality samples \n",
    "    geno = allel.GenotypeArray(vcf['calldata/GT'])\n",
    "    geno = geno.compress(sample_mask, axis=1)\n",
    "    pos = vcf['variants/POS']\n",
    "    contig = vcf['variants/CHROM']\n",
    "    indel = vcf['variants/INDEL']\n",
    "    \n",
    "    # remove indels \n",
    "    geno = geno.compress(~indel, axis=0)\n",
    "    pos = pos[~indel]\n",
    "    contig = contig[~indel]\n",
    "    ref = vcf['variants/REF'][~indel]\n",
    "    alt = vcf['variants/ALT'][~indel]\n",
    "    ann = read_ANN_field(vcf_path)[~indel]\n",
    "    \n",
    "    # filter on depth\n",
    "    if depth_filter:\n",
    "        depth = vcf['variants/DP']\n",
    "        mask = depth > depth_filter\n",
    "        geno = geno.compress(mask, axis=0)\n",
    "        pos = pos[mask]\n",
    "        contig = contig[mask]\n",
    "        ref = ref[mask]\n",
    "        alt = alt[mask]\n",
    "        ann = ann[mask]\n",
    "    \n",
    "    return geno, pos, contig, samples[sample_mask], ref, alt, ann\n",
    "\n",
    "def read_ANN_field(vcf_file):\n",
    "    anns = []\n",
    "    with open(vcf_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue  # Skip header lines\n",
    "            fields = line.strip().split('\\t')\n",
    "            info_field = fields[7]\n",
    "            info_pairs = info_field.split(';')\n",
    "            ann_value = None\n",
    "            for pair in info_pairs:\n",
    "                if pair.startswith('ANN='):\n",
    "                    ann_value = pair.split('=')[1]\n",
    "                    break\n",
    "            anns.append(ann_value)\n",
    "\n",
    "    return np.array(anns)\n",
    "\n",
    "def vcf_to_snp_dataframe(vcf_path, metadata):\n",
    "\n",
    "    geno, pos, contig, samples, ref, alt, ann = load_vcf(vcf_path=vcf_path, metadata=metadata)\n",
    "    \n",
    "    # make dataframe of variant positions and merge with bed\n",
    "    snp_df = pd.DataFrame({'contig':contig, 'pos':pos, 'ref':ref, 'alt':[list(a[a != \"\"]) for a in alt], 'ann':ann})\n",
    "\n",
    "    snp_df = snp_df.explode('alt').reset_index().rename(columns={'index':'variant_index'})\n",
    "    snp_df = snp_df.assign(alt_index=snp_df.groupby('pos').cumcount() + 1) \n",
    "    snp_df = snp_df.assign(label=lambda x: x.pos.astype(str) + \" | \" +  x.alt.fillna('NA'))\n",
    "    snp_df.head(2)\n",
    "\n",
    "    # split and find correct annotation \n",
    "    df = snp_df.assign(ann=lambda x: x.ann.str.split(\",\"))\n",
    "    anns = []\n",
    "    for i, row in df.iterrows():\n",
    "        alt = row['alt']\n",
    "        if row['ann'] == None:\n",
    "            ann = \"\"\n",
    "        else:\n",
    "            # keep only RD Vgsc annotations\n",
    "            if 'AGAP004707' in ','.join(row['ann']):\n",
    "                row['ann'] = [a for a in row['ann'] if \"AGAP004707-RD\" in a]\n",
    "\n",
    "            ann = ','.join([a for a in row['ann'] if a.startswith(alt)])\n",
    "        anns.append(ann)\n",
    "\n",
    "    snp_df = snp_df.assign(ann=anns)\n",
    "    \n",
    "    return snp_df, geno\n",
    "\n",
    "def calculate_frequencies_cohort(snp_df, metadata, geno, cohort_col, af_filter, missense_filter):\n",
    "    np.seterr(all=\"ignore\")\n",
    "    \n",
    "    df = snp_df.copy()\n",
    "    \n",
    "    # get indices of each cohort\n",
    "    coh_dict = {}\n",
    "    cohs = metadata[cohort_col].unique()\n",
    "    cohs = cohs[~pd.isnull(cohs)]\n",
    "    for coh in cohs:\n",
    "        coh_dict[coh] = np.where(metadata[cohort_col] == coh)[0]\n",
    "    \n",
    "    # get allele counts for each population\n",
    "    ac = geno.count_alleles_subpops(coh_dict, max_allele=3)\n",
    "    \n",
    "    for coh in cohs:\n",
    "        total_counts = []\n",
    "        alt_counts = []\n",
    "        for i, row in df.iterrows():\n",
    "            var_idx = row['variant_index']\n",
    "            alt_idx = row['alt_index']\n",
    "            total_counts.append(ac[coh][var_idx,:].sum())\n",
    "            alt_counts.append(ac[coh][var_idx, alt_idx])\n",
    "\n",
    "        df.loc[:, f'count_{coh}'] = np.array(alt_counts)\n",
    "        df.loc[:, f'frq_{coh}'] = np.round(np.array(alt_counts)/np.array(total_counts), 3)\n",
    "    \n",
    "    freq_df = df.set_index('label').filter(like='frq')\n",
    "    \n",
    "    ann_df = snp_df.ann.str.split(\"|\", expand=True).iloc[:, :11].drop(columns=[0,7,8])\n",
    "    ann_df.columns = ['type', 'effect', 'gene', 'geneID', 'modifier', 'transcript', 'base_change', 'aa_change']\n",
    "    snp_df = pd.concat([snp_df[['contig', 'pos', 'ref', 'alt']], ann_df], axis=1)\n",
    "    snp_freq_df = pd.concat([snp_df, freq_df.reset_index()], axis=1)\n",
    "\n",
    "    snp_freq_df = snp_freq_df.assign(label=\n",
    "                  lambda x: x.contig + \" | \" + x.geneID + \" | \" + x.pos.astype(str) + \" | \" + x.aa_change.str.replace(\"p.\", \"\") + \" | \" + x.alt.fillna(\" \")\n",
    "                 )\n",
    "    \n",
    "    if af_filter:\n",
    "        af_pass = (snp_freq_df.filter(like='frq') > 0.05).any(axis=1)\n",
    "        snp_freq_df = snp_freq_df[af_pass]\n",
    "    \n",
    "    if missense_filter:\n",
    "        snp_freq_df = snp_freq_df.query(\"type == 'missense_variant'\")\n",
    "    \n",
    "    return snp_freq_df.set_index('label')\n",
    "\n",
    "def plot_allele_frequencies(df, cohort_col):\n",
    "        \n",
    "    fig = px.imshow(\n",
    "            img=df,\n",
    "            zmin=0,\n",
    "            zmax=1,\n",
    "            width=np.max([800, df.shape[1] * 100]),\n",
    "            height=df.shape[0] * 20,\n",
    "            text_auto=True,\n",
    "            aspect=1,\n",
    "            color_continuous_scale=\"Reds\",\n",
    "            title=f\"Allele frequencies | by {cohort_col}\",\n",
    "        template='simple_white'\n",
    "        )\n",
    "    fig.update(layout_coloraxis_showscale=False)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4571035",
   "metadata": {
    "tags": [
     "remove-input",
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = 'ag-vampir-002'\n",
    "metadata_path = \"../../results/config/metadata.qcpass.tsv\"\n",
    "cohort_cols = 'strain' #taxon,location'\n",
    "bed_path = \"../../config/ag-vampir.bed\"\n",
    "vcf_path = \"../../results/vcfs/targets/ag-vampir-002.annot.vcf\"\n",
    "wkdir = \"../..\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d349d15",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "### Plotting allele frequencies\n",
    "\n",
    "This page shows allele frequencies in each cohort of the SNPs genotyped in the amplicon sequencing protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee8c132c",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "cohort_cols = cohort_cols.split(\",\")\n",
    "\n",
    "bed_df = pd.read_csv(bed_path, sep=\"\\t\", header=None, names=['contig', 'start', 'end', 'ref', 'alt', 'amplicon_id', 'mutation'])\n",
    "\n",
    "# load metadata\n",
    "if metadata_path.endswith('.xlsx'):\n",
    "    metadata = pd.read_excel(metadata_path, engine='openpyxl')\n",
    "elif metadata_path.endswith('.tsv'):\n",
    "    metadata = pd.read_csv(metadata_path, sep=\"\\t\")\n",
    "elif metadata_path.endswith('.csv'):\n",
    "    metadata = pd.read_csv(metadata_path, sep=\",\")\n",
    "else:\n",
    "    raise ValueError(\"Metadata file must be .xlsx or .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19a63cb1",
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snagi/lstm_projects/ampseq-agvampir002/.snakemake/conda/3b1c9fccc6ddcee649a430b64373b071_/lib/python3.12/site-packages/allel/io/vcf_read.py:1732: UserWarning: invalid INFO header: '##INFO=<ID=VDB,Number=1,Type=Float,Description=\"Variant Distance Bias for filtering splice-site artefacts in RNA-seq data (bigger is better)\",Version=\"3\">\\n'\n",
      "  warnings.warn('invalid INFO header: %r' % header)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'sample_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_549856/1489535494.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msnp_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvcf_to_snp_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvcf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfrq_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcohort_col\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcohort_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_549856/3790750773.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(vcf_path, metadata)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvcf_to_snp_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvcf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mgeno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvcf_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvcf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# make dataframe of variant positions and merge with bed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0msnp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'contig'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcontig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ref'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'alt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ann'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_549856/3790750773.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(vcf_path, metadata, depth_filter)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# load vcf and get genotypes and positions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mvcf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_vcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvcf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvcf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# keep only samples in qcpass metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0msample_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvcf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# remove low quality samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mgeno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenotypeArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvcf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'calldata/GT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lstm_projects/ampseq-agvampir002/.snakemake/conda/3b1c9fccc6ddcee649a430b64373b071_/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'sample_id'"
     ]
    }
   ],
   "source": [
    "snp_df, geno = vcf_to_snp_dataframe(vcf_path, metadata)\n",
    "\n",
    "frq_dfs = []\n",
    "for cohort_col in cohort_cols:\n",
    "    \n",
    "    freq_df = calculate_frequencies_cohort(\n",
    "        snp_df=snp_df, \n",
    "        metadata=metadata,\n",
    "        geno=geno, \n",
    "        cohort_col=cohort_col,\n",
    "        af_filter=None,\n",
    "        missense_filter=False\n",
    "    )\n",
    "    frq_dfs.append(freq_df.reset_index(drop=True))\n",
    "\n",
    "    plot_allele_frequencies(\n",
    "        df=freq_df.filter(like='frq_'),\n",
    "        cohort_col=cohort_col\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece08d55",
   "metadata": {},
   "source": [
    "#### SNP frequency summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ffa152",
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "snp_df = pd.concat([snp_df] + frq_dfs, axis=1)\n",
    "snp_df.to_csv(f\"{wkdir}/results/snp_frequencies_summary.tsv\", sep=\"\\t\")\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3267a7d",
   "metadata": {},
   "source": [
    "#### Allele frequencies of any SNPs across amplicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350de0cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vcf_path = f\"{wkdir}/results/vcfs/amplicons/{dataset}.annot.vcf\"\n",
    "cohort_col = cohort_cols[0]\n",
    "\n",
    "snp_df, geno = vcf_to_snp_dataframe(vcf_path, metadata)\n",
    "\n",
    "snp_freq_df = calculate_frequencies_cohort(\n",
    "    snp_df=snp_df, \n",
    "    metadata=metadata,\n",
    "    geno=geno, \n",
    "    cohort_col=cohort_col, \n",
    "    af_filter=0.05,\n",
    "    missense_filter=True\n",
    ")   \n",
    "\n",
    "snp_freq_df = snp_freq_df.filter(like='frq')\n",
    "snp_freq_df.columns = snp_freq_df.columns.str.replace(\"frq_\", \"\")\n",
    "\n",
    "plot_allele_frequencies(\n",
    "    df=snp_freq_df,\n",
    "    cohort_col=cohort_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87cff95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
