{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3f429b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import allel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_vcf(vcf_path, metadata, depth_filter=None):\n",
    "    \"\"\"\n",
    "    Load VCF and filter poor-quality samples\n",
    "    \"\"\"\n",
    "      \n",
    "    # load vcf and get genotypes and positions\n",
    "    vcf = allel.read_vcf(vcf_path, fields='*')\n",
    "    samples = vcf['samples']\n",
    "    # keep only samples in qcpass metadata \n",
    "    sample_mask = np.isin(vcf['samples'], metadata.sampleID)\n",
    "    \n",
    "    # remove low quality samples \n",
    "    geno = allel.GenotypeArray(vcf['calldata/GT'])\n",
    "    geno = geno.compress(sample_mask, axis=1)\n",
    "    pos = vcf['variants/POS']\n",
    "    contig = vcf['variants/CHROM']\n",
    "    indel = vcf['variants/INDEL']\n",
    "    \n",
    "    # remove indels \n",
    "    geno = geno.compress(~indel, axis=0)\n",
    "    pos = pos[~indel]\n",
    "    contig = contig[~indel]\n",
    "    ref = vcf['variants/REF'][~indel]\n",
    "    alt = vcf['variants/ALT'][~indel]\n",
    "    ann = read_ANN_field(vcf_path)[~indel]\n",
    "    \n",
    "    # filter on depth\n",
    "    if depth_filter:\n",
    "        depth = vcf['variants/DP']\n",
    "        mask = depth > depth_filter\n",
    "        geno = geno.compress(mask, axis=0)\n",
    "        pos = pos[mask]\n",
    "        contig = contig[mask]\n",
    "        ref = ref[mask]\n",
    "        alt = alt[mask]\n",
    "        ann = ann[mask]\n",
    "    \n",
    "    return geno, pos, contig, samples[sample_mask], ref, alt, ann\n",
    "\n",
    "def read_ANN_field(vcf_file):\n",
    "    anns = []\n",
    "    with open(vcf_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue  # Skip header lines\n",
    "            fields = line.strip().split('\\t')\n",
    "            info_field = fields[7]\n",
    "            info_pairs = info_field.split(';')\n",
    "            ann_value = None\n",
    "            for pair in info_pairs:\n",
    "                if pair.startswith('ANN='):\n",
    "                    ann_value = pair.split('=')[1]\n",
    "                    break\n",
    "            anns.append(ann_value)\n",
    "\n",
    "    return np.array(anns)\n",
    "\n",
    "def vcf_to_snp_dataframe(vcf_path, metadata):\n",
    "\n",
    "    geno, pos, contig, samples, ref, alt, ann = load_vcf(vcf_path=vcf_path, metadata=metadata)\n",
    "    \n",
    "    # make dataframe of variant paositions and merge with bed\n",
    "    snp_df = pd.DataFrame({'contig':contig, 'pos':pos, 'ref':ref, 'alt':[list(a[a != \"\"]) for a in alt], 'ann':ann})\n",
    "\n",
    "    snp_df = snp_df.explode('alt').reset_index().rename(columns={'index':'variant_index'})\n",
    "    snp_df = snp_df.assign(alt_index=snp_df.groupby('pos').cumcount() + 1) \n",
    "    snp_df = snp_df.assign(label=lambda x: x.pos.astype(str) + \" | \" +  x.alt.fillna('NA'))\n",
    "    snp_df.head(2)\n",
    "\n",
    "    # split and find correct annotation \n",
    "    df = snp_df.assign(ann=lambda x: x.ann.str.split(\",\"))\n",
    "    anns = []\n",
    "    for i, row in df.iterrows():\n",
    "        alt = row['alt']\n",
    "        if row['ann'] == None:\n",
    "            ann = \"\"\n",
    "        else:\n",
    "            # keep only RD Vgsc annotations\n",
    "            if 'AGAP004707' in ','.join(row['ann']):\n",
    "                row['ann'] = [a for a in row['ann'] if \"AGAP004707-RD\" in a]\n",
    "\n",
    "            ann = ','.join([a for a in row['ann'] if a.startswith(alt)])\n",
    "        anns.append(ann)\n",
    "\n",
    "    snp_df = snp_df.assign(ann=anns)\n",
    "    \n",
    "    return snp_df, geno\n",
    "\n",
    "def calculate_frequencies_cohort(snp_df, metadata, geno, cohort_col, af_filter, missense_filter):\n",
    "    np.seterr(all=\"ignore\")\n",
    "    \n",
    "    df = snp_df.copy()\n",
    "    \n",
    "    # get indices of each cohort\n",
    "    coh_dict = {}\n",
    "    cohs = metadata[cohort_col].unique()\n",
    "    cohs = cohs[~pd.isnull(cohs)]\n",
    "    for coh in cohs:\n",
    "        coh_dict[coh] = np.where(metadata[cohort_col] == coh)[0]\n",
    "    \n",
    "    # get allele counts for each population\n",
    "    ac = geno.count_alleles_subpops(coh_dict, max_allele=3)\n",
    "    \n",
    "    for coh in cohs:\n",
    "        total_counts = []\n",
    "        alt_counts = []\n",
    "        for i, row in df.iterrows():\n",
    "            var_idx = row['variant_index']\n",
    "            alt_idx = row['alt_index']\n",
    "            total_counts.append(ac[coh][var_idx,:].sum())\n",
    "            alt_counts.append(ac[coh][var_idx, alt_idx])\n",
    "\n",
    "        df.loc[:, f'count_{coh}'] = np.array(alt_counts)\n",
    "        df.loc[:, f'frq_{coh}'] = np.round(np.array(alt_counts)/np.array(total_counts), 3)\n",
    "    \n",
    "    freq_df = df.set_index('label').filter(like='frq')\n",
    "    \n",
    "    ann_df = snp_df.ann.str.split(\"|\", expand=True).iloc[:, :11].drop(columns=[0,7,8])\n",
    "    ann_df.columns = ['type', 'effect', 'gene', 'geneID', 'modifier', 'transcript', 'base_change', 'aa_change']\n",
    "    snp_df = pd.concat([snp_df[['contig', 'pos', 'ref', 'alt']], ann_df], axis=1)\n",
    "    snp_freq_df = pd.concat([snp_df, freq_df.reset_index()], axis=1)\n",
    "\n",
    "    snp_freq_df = snp_freq_df.assign(label=\n",
    "                  lambda x: x.contig + \" | \" + x.geneID + \" | \" + x.pos.astype(str) + \" | \" + x.aa_change.str.replace(\"p.\", \"\") + \" | \" + x.alt.fillna(\" \")\n",
    "                 )\n",
    "    \n",
    "    if af_filter:\n",
    "        af_pass = (snp_freq_df.filter(like='frq') > 0.05).any(axis=1)\n",
    "        snp_freq_df = snp_freq_df[af_pass]\n",
    "    \n",
    "    if missense_filter:\n",
    "        snp_freq_df = snp_freq_df.query(\"type == 'missense_variant'\")\n",
    "    \n",
    "    return snp_freq_df.set_index('label')\n",
    "\n",
    "def plot_allele_frequencies(df, cohort_col):\n",
    "        \n",
    "    fig = px.imshow(\n",
    "            img=df,\n",
    "            zmin=0,\n",
    "            zmax=1,\n",
    "            width=np.max([500, df.shape[1] * 100]),\n",
    "            height=df.shape[0] * 20,\n",
    "            text_auto=True,\n",
    "            aspect=1,\n",
    "            color_continuous_scale=\"Reds\",\n",
    "            title=f\"Allele frequencies | by {cohort_col}\",\n",
    "        template='simple_white'\n",
    "        )\n",
    "    fig.update(layout_coloraxis_showscale=False)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4571035",
   "metadata": {
    "tags": [
     "remove-input",
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = 'ampseq-colony'\n",
    "metadata_path = \"../../results/config/metadata.qcpass.tsv\"\n",
    "cohort_cols = 'strain' #taxon,location'\n",
    "bed_path = \"../../config/ag-vampir.bed\"\n",
    "vcf_path = \"../../results/vcfs/targets/ampseq-colony.annot.vcf\"\n",
    "wkdir = \"../..\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d349d15",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "### Plotting allele frequencies\n",
    "\n",
    "This page shows allele frequencies in each cohort of the SNPs genotyped in the amplicon sequencing protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee8c132c",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "cohort_cols = cohort_cols.split(\",\")\n",
    "\n",
    "bed_df = pd.read_csv(bed_path, sep=\"\\t\", header=None, names=['contig', 'start', 'pos', 'amplicon_id', 'target_id'])\n",
    "\n",
    "# load metadata\n",
    "if metadata_path.endswith('.xlsx'):\n",
    "    metadata = pd.read_excel(metadata_path, engine='openpyxl')\n",
    "elif metadata_path.endswith('.tsv'):\n",
    "    metadata = pd.read_csv(metadata_path, sep=\"\\t\")\n",
    "elif metadata_path.endswith('.csv'):\n",
    "    metadata = pd.read_csv(metadata_path, sep=\",\")\n",
    "else:\n",
    "    raise ValueError(\"Metadata file must be .xlsx or .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19a63cb1",
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snagi/miniconda3/lib/python3.11/site-packages/allel/io/vcf_read.py:1732: UserWarning: invalid INFO header: '##INFO=<ID=VDB,Number=1,Type=Float,Description=\"Variant Distance Bias for filtering splice-site artefacts in RNA-seq data (bigger is better)\",Version=\"3\">\\n'\n",
      "  warnings.warn('invalid INFO header: %r' % header)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m frq_dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cohort_col \u001b[38;5;129;01min\u001b[39;00m cohort_cols:\n\u001b[0;32m----> 6\u001b[0m     freq_df \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_frequencies_cohort\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43msnp_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnp_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeno\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeno\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcohort_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcohort_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43maf_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissense_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     frq_dfs\u001b[38;5;241m.\u001b[39mappend(freq_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m     16\u001b[0m     plot_allele_frequencies(\n\u001b[1;32m     17\u001b[0m         df\u001b[38;5;241m=\u001b[39mfreq_df\u001b[38;5;241m.\u001b[39mfilter(like\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrq_\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     18\u001b[0m         cohort_col\u001b[38;5;241m=\u001b[39mcohort_col\n\u001b[1;32m     19\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[1], line 116\u001b[0m, in \u001b[0;36mcalculate_frequencies_cohort\u001b[0;34m(snp_df, metadata, geno, cohort_col, af_filter, missense_filter)\u001b[0m\n\u001b[1;32m    114\u001b[0m     alt_idx \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malt_index\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    115\u001b[0m     total_counts\u001b[38;5;241m.\u001b[39mappend(ac[coh][var_idx,:]\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m--> 116\u001b[0m     alt_counts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mac\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcoh\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvar_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt_idx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    118\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(alt_counts)\n\u001b[1;32m    119\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrq_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(np\u001b[38;5;241m.\u001b[39marray(alt_counts)\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(total_counts), \u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/allel/model/ndarray.py:2624\u001b[0m, in \u001b[0;36mAlleleCountsArray.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[0;32m-> 2624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindex_allele_counts_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/allel/model/generic.py:143\u001b[0m, in \u001b[0;36mindex_allele_counts_array\u001b[0;34m(ac, item, cls)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindex_allele_counts_array\u001b[39m(ac, item, \u001b[38;5;28mcls\u001b[39m):\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# apply indexing operation on underlying values\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# decide whether to wrap the result as HaplotypeArray\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     wrap_array \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;28mhasattr\u001b[39m(out, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m  \u001b[38;5;66;03m# dimensionality preserved\u001b[39;00m\n\u001b[1;32m    148\u001b[0m         ac\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m  \u001b[38;5;66;03m# number of alleles preserved\u001b[39;00m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m contains_newaxis(item)\n\u001b[1;32m    150\u001b[0m     )\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "snp_df, geno = vcf_to_snp_dataframe(vcf_path, metadata)\n",
    "\n",
    "frq_dfs = []\n",
    "for cohort_col in cohort_cols:\n",
    "    \n",
    "    freq_df = calculate_frequencies_cohort(\n",
    "        snp_df=snp_df, \n",
    "        metadata=metadata,\n",
    "        geno=geno, \n",
    "        cohort_col=cohort_col,\n",
    "        af_filter=None,\n",
    "        missense_filter=False\n",
    "    )\n",
    "    frq_dfs.append(freq_df.reset_index(drop=True))\n",
    "\n",
    "    plot_allele_frequencies(\n",
    "        df=freq_df.filter(like='frq_'),\n",
    "        cohort_col=cohort_col\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece08d55",
   "metadata": {},
   "source": [
    "#### SNP frequency summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72ffa152",
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snp_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.max_rows\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m snp_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43msnp_df\u001b[49m] \u001b[38;5;241m+\u001b[39m frq_dfs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m snp_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwkdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/results/snp_frequencies_summary.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m snp_df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'snp_df' is not defined"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "snp_df = pd.concat([snp_df] + frq_dfs, axis=1)\n",
    "snp_df.to_csv(f\"{wkdir}/results/snp_frequencies_summary.tsv\", sep=\"\\t\")\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3267a7d",
   "metadata": {},
   "source": [
    "#### Allele frequencies of any SNPs across amplicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350de0cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vcf_path = f\"{wkdir}/results/vcfs/amplicons/{dataset}.annot.vcf\"\n",
    "cohort_col = cohort_cols[0]\n",
    "\n",
    "snp_df, geno = vcf_to_snp_dataframe(vcf_path, metadata)\n",
    "\n",
    "snp_freq_df = calculate_frequencies_cohort(\n",
    "    snp_df=snp_df, \n",
    "    metadata=metadata,\n",
    "    geno=geno, \n",
    "    cohort_col=cohort_col, \n",
    "    af_filter=0.05,\n",
    "    missense_filter=True\n",
    ")   \n",
    "\n",
    "snp_freq_df = snp_freq_df.filter(like='frq')\n",
    "snp_freq_df.columns = snp_freq_df.columns.str.replace(\"frq_\", \"\")\n",
    "\n",
    "plot_allele_frequencies(\n",
    "    df=snp_freq_df,\n",
    "    cohort_col=cohort_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87cff95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
