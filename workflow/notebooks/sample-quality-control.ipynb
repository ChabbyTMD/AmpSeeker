{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8356ae5b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import allel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308ef38",
   "metadata": {
    "tags": [
     "remove-input",
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "metadata_path = '../../config/metadata.tsv'\n",
    "bed_targets_path = \"../../config/ag-vampir.bed\"\n",
    "vcf_path = \"../../results/vcfs/targets/ampseq-vigg-01.annot.vcf\"\n",
    "wkdir = \"../..\"\n",
    "\n",
    "sample_total_reads_threshold = 250\n",
    "amplicon_total_reads_threshold = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a842a6",
   "metadata": {},
   "source": [
    "# Sample quality control \n",
    "\n",
    "In this notebook, we perform quality control on samples, removing samples with very low depth or elevated heterozygosity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1552f7",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(metadata_path , sep=\"\\t\")\n",
    "\n",
    "panel_metadata = pd.read_csv(\n",
    "    bed_targets_path, \n",
    "    sep=\"\\t\", \n",
    "    header=None, \n",
    "    names=['contig', 'start', 'end', 'amplicon', 'mutation']\n",
    ")\n",
    "\n",
    "vcf = allel.read_vcf(vcf_path, fields='*')\n",
    "\n",
    "samples = vcf['samples']\n",
    "contigs = vcf['variants/CHROM']\n",
    "geno = allel.GenotypeArray(vcf['calldata/GT'])\n",
    "pos = vcf['variants/POS']\n",
    "ref = vcf['variants/REF']\n",
    "depth = vcf['variants/DP']\n",
    "qual = vcf['variants/QUAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48786245",
   "metadata": {},
   "source": [
    "## Coverage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815337c7",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "target_covs = []\n",
    "x_ratios = []\n",
    "for sample in metadata.sampleID:\n",
    "    target_cov = pd.read_csv(f\"{wkdir}/results/coverage/{sample}.regions.bed.gz\", sep=\"\\t\", header=None, names=['contig', 'start', 'end', 'amplicon', 'depth', 'sampleID'])\n",
    "    target_cov = target_cov.assign(sampleID=sample)\n",
    "    target_covs.append(target_cov)\n",
    "    \n",
    "    # x-autosome ratio\n",
    "    contig_depth = target_cov.groupby('contig').agg({'depth':'sum'})\n",
    "    x_ratios.append((contig_depth.loc[['2L', '2R', '3L', '3R']].sum() / contig_depth.loc['X']).iloc[0])\n",
    "    \n",
    "target_cov_df = pd.concat(target_covs, axis=0)\n",
    "target_cov_df = target_cov_df.merge(panel_metadata, how='left', on=['contig', 'start', 'end', 'amplicon'])\n",
    "\n",
    "sample_cov_df = target_cov_df.groupby('sampleID').agg({'depth':'sum'}).reset_index()\n",
    "\n",
    "fig = px.histogram(sample_cov_df, x='depth', nbins=500, template='simple_white', \n",
    "                   width=800, height=300, title='Histogram of total read counts per sample')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b833b421",
   "metadata": {},
   "source": [
    "How many samples fall below the threshold for total reads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a945c4",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "exclude_samples_depth = sample_cov_df.query(\"depth < @sample_total_reads_threshold\")['sampleID']\n",
    "print(f\"Removing {len(exclude_samples_depth)} samples due to low total depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d5213",
   "metadata": {},
   "source": [
    "#### Total reads per target SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375455d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d9efa",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "amplicon_cov_df = target_cov_df.groupby('mutation').agg({'depth':'sum'}).reset_index()\n",
    "\n",
    "fig = px.histogram(amplicon_cov_df, x='depth', nbins=200, color='mutation', template='simple_white', \n",
    "                   width=800, height=350, \n",
    "                   title='Histogram of total read counts per SNP target')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7079202",
   "metadata": {},
   "source": [
    "Which target SNPs have lower total depth than the amplicon threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_targets_depth = amplicon_cov_df.query(\"depth < @amplicon_total_reads_threshold\")['mutation']\n",
    "print(f\"Removing {len(exclude_targets_depth)} target SNPs due to low total depth\")\n",
    "\n",
    "pd.DataFrame(exclude_targets_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9371586",
   "metadata": {},
   "source": [
    "### Number of missing calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6824f5",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "exclude_samples_missing_calls = samples[(geno.is_missing().sum(axis=0) > 40)]\n",
    "print(f\"{len(exclude_samples_missing_calls)} samples have more than 40 missing calls overall out of all possible target SNPs\")\n",
    "\n",
    "a = exclude_samples_missing_calls\n",
    "b = exclude_samples_depth\n",
    "\n",
    "# how many genes are shared between the exclude missing calls and depth lists \n",
    "overlap = len(set(a) & set(b))\n",
    "\n",
    "print(f\"{overlap}/{len(exclude_samples_missing_calls)} of these are also present in the low depth samples to be excluded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5c9601",
   "metadata": {},
   "source": [
    "### Autosome / Sex chromosome coverage ratios\n",
    "\n",
    "Females will have a lower ratio of autosomes:x, and males will have a higher ratio. Its not clear whether we can use this yet to sex samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84386ac",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "x_ratio_df = pd.DataFrame({'sampleID':metadata.sampleID, 'x_ratio':x_ratios})\n",
    "x_ratio_df = x_ratio_df.query(\"sampleID not in @exclude_samples_depth\")\n",
    "\n",
    "fig = px.histogram(x_ratio_df, x='x_ratio', color='sampleID', template='simple_white', nbins=1000, width=800, height=300)\n",
    "fig.update_xaxes(range=(0,20), title=dict(text='Autosome / X depth ratio'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a5b5a",
   "metadata": {},
   "source": [
    "### Sample heterozygosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703550f9",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def calc_heterozygosity(gt, gt_samples):\n",
    "    from tqdm.notebook import tqdm\n",
    "    \n",
    "    het_per_sample = [np.nanmean(allel.heterozygosity_observed(gt[:, [i], :])) for i in tqdm(range(gt.shape[1]))]\n",
    "    het_df = pd.DataFrame({'sampleID':gt_samples, 'heterozygosity':het_per_sample})\n",
    "    return het_df.set_index(\"sampleID\")\n",
    "\n",
    "het_df = calc_heterozygosity(gt=geno, gt_samples=samples).reset_index()\n",
    "het_df = het_df.merge(metadata)\n",
    "\n",
    "fig = px.bar(\n",
    "    het_df, \n",
    "    x='sampleID', \n",
    "    y='heterozygosity', \n",
    "    color='location', \n",
    "    template='simple_white', \n",
    "    title=\"Individual sample heterozygosity\", \n",
    "    height=400,\n",
    "    width=900\n",
    ")\n",
    "\n",
    "fig2  = px.histogram(\n",
    "    het_df, \n",
    "    x='heterozygosity', \n",
    "    color='location', \n",
    "    template='simple_white', \n",
    "    title=\"Histogram of sample heterozygosity\", \n",
    "    height=400,\n",
    "    width=900\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dc96b6",
   "metadata": {},
   "source": [
    "#### Locate heterozygosity outliers\n",
    "\n",
    "We then find samples within each cohort which have a heterozygosity (2.5 * IQR) higher than the 75% quantile, to exclude samples with very high heterozygosity for their cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058a32d5",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.stats import iqr\n",
    "\n",
    "iqr_multiplier = 2.5 # determines how strict we are in throwing out outliers \n",
    "\n",
    "exclude_samples_heterozygosity = []\n",
    "for coh in het_df.location.unique():\n",
    "    df = het_df.query(\"location == @coh\")\n",
    "    hets = df.heterozygosity\n",
    "    \n",
    "    threshold = np.nanquantile(hets, 0.75) + (iqr_multiplier * iqr(hets, nan_policy='omit'))\n",
    "    \n",
    "    if any(hets > threshold):\n",
    "        exclude_samples_heterozygosity.extend(df.query(\"heterozygosity > @threshold\").sampleID.to_list())\n",
    "    \n",
    "    print(f\"For {coh} the heterozygosity threshold is {np.round(threshold, 3)}, out of {len(hets)} samples, {(hets > threshold).sum()} are outliers\")\n",
    "\n",
    "print(f\"\\nRemoving {len(exclude_samples_heterozygosity)} samples in total due to high heterozygosity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb559dbd",
   "metadata": {},
   "source": [
    "### Summary of samples to exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed83de9",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "exclude_samples = np.unique(exclude_samples_depth.to_list() + exclude_samples_heterozygosity + list(exclude_samples_missing_calls))\n",
    "removed_metadata = metadata.query(\"sampleID in @exclude_samples\").location.value_counts().to_frame().reset_index()\n",
    "\n",
    "removed_metadata = removed_metadata.set_index('location').T\n",
    "tot = removed_metadata.sum(axis=1)\n",
    "removed_metadata = removed_metadata.assign(total=tot).T\n",
    "\n",
    "removed_metadata.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b980bc",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "new_metadata = metadata.query(\"sampleID not in @exclude_samples\")\n",
    "new_metadata.to_csv(f\"{wkdir}/results/config/metadata.qcpass.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b96b94",
   "metadata": {},
   "source": [
    "####  Sample QC complete!\n",
    "A new metadata file with low-quality samples removed has been written to results/config/ :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80286e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e8d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b85103",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "### Variant Hardy-Weinberg equilibrium\n",
    "# from itertools import combinations\n",
    "\n",
    "# possible_alleles = [[0,0], [0,1], [1,1], [-1,-1], [1,2]]\n",
    "# possible_alleles = np.unique(np.array(list(combinations(np.repeat([-1,0,1,2,3], 2), 2))), axis=0)\n",
    "\n",
    "# from collections import defaultdict\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# def count_alleles_to_df(geno, pos, contig):\n",
    "#     from collections import defaultdict\n",
    "#     from tqdm.notebook import tqdm\n",
    "\n",
    "#     assert geno.shape[0] == pos.shape[0]\n",
    "\n",
    "#     di = {}\n",
    "#     for i, p in tqdm(enumerate(pos)):\n",
    "#         counter = defaultdict(int)\n",
    "\n",
    "#         for allele in possible_alleles:\n",
    "#             allele_str = '/'.join(allele.astype(str))\n",
    "#             for idx in range(geno.shape[1]):\n",
    "#                 if all(geno[i, idx] == allele):\n",
    "#                     counter[allele_str] += 1\n",
    "#                 else:\n",
    "#                     counter[allele_str] += 0\n",
    "#                 di[f\"{contig[i]}:{p}\"] = counter\n",
    "                \n",
    "#     return pd.DataFrame(di).reset_index().rename(columns={'index':'genotype'})\n",
    "\n",
    "# geno_count_df = count_alleles_to_df(geno=geno, pos=pos, contig=contigs)\n",
    "# geno_count_df = geno_count_df.query(\"~genotype.str.contains('-1')\")\n",
    "\n",
    "# df = geno_count_df.set_index('genotype')\n",
    "\n",
    "# import snphwe\n",
    "\n",
    "# snphwe.snphwe(gn_counts[1], gn_counts[0],  gn_counts[2])\n",
    "\n",
    "# not bulletproof - takes 3 most common counts for a given snp\n",
    "# if quite multiallelic things probably go wrong \n",
    "# for var in df.columns:\n",
    "#     allele_idxs = np.argpartition(df[var], -3)[-3:]\n",
    "#     gn_counts = df[var].iloc[allele_idxs].sort_index()\n",
    "    \n",
    "#     if (gn_counts != 0).sum() == 1:\n",
    "#         res = 'NaN'\n",
    "#     else:\n",
    "#         res = snphwe.snphwe(gn_counts[1], gn_counts[0],  gn_counts[2])\n",
    "#     print(gn_counts, res, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
