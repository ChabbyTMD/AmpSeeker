{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c01954f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import allel\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import plotly.express as px\n",
    "\n",
    "def load_vcf(vcf_path, metadata, query=None):\n",
    "    \"\"\"\n",
    "    Load VCF and filter poor-quality samples\n",
    "    \"\"\"\n",
    "       \n",
    "    # load vcf and get genotypes and positions\n",
    "    vcf = allel.read_vcf(vcf_path, fields=\"*\")\n",
    "    samples = vcf['samples']\n",
    "    # keep only samples in qcpass metadata \n",
    "    sample_mask = np.isin(vcf['samples'], metadata.sample_id)\n",
    "    \n",
    "    # remove low quality samples \n",
    "    geno = allel.GenotypeArray(vcf['calldata/GT'])\n",
    "    geno = geno.compress(sample_mask, axis=1)\n",
    "    pos = vcf['variants/POS']\n",
    "    contig = vcf['variants/CHROM']\n",
    "    indel = vcf['variants/INDEL']\n",
    "    \n",
    "    # remove any indels \n",
    "    geno = geno.compress(~indel, axis=0)\n",
    "    pos = pos[~indel]\n",
    "    contig = contig[~indel]\n",
    "\n",
    "    metadata = metadata.set_index('sample_id')\n",
    "    samples = samples[sample_mask]\n",
    "\n",
    "    if query:\n",
    "        mask = metadata.eval(query)\n",
    "        metadata = metadata[mask]\n",
    "        samples = samples[mask]\n",
    "        geno = geno.compress(mask, axis=1)\n",
    "    \n",
    "    return geno, pos, contig, metadata.loc[samples, :].reset_index()\n",
    "\n",
    "def pca(metadata, vcf_path, n_components = 6, query=None):\n",
    "    \"\"\"\n",
    "    Load genotype data and run PCA \n",
    "    \"\"\"\n",
    "\n",
    "    geno, pos, contig, metadata = load_vcf(vcf_path, metadata, query)\n",
    "    \n",
    "    gn_alt = geno.to_n_alt()\n",
    "\n",
    "    print(\"removing any invariant sites\")\n",
    "    loc_var = np.any(gn_alt != gn_alt[:, 0, np.newaxis], axis=1)\n",
    "    gn_var = np.compress(loc_var, gn_alt, axis=0)\n",
    "    \n",
    "    coords, model = allel.pca(gn_var, n_components=n_components)\n",
    "    # flip axes back so PC1 is same orientation in each window \n",
    "    for i in range(n_components):\n",
    "        c = coords[:, i]\n",
    "    if np.abs(c.min()) > np.abs(c.max()):\n",
    "        coords[:, i] = c * -1\n",
    "    \n",
    "    pca_df = pd.DataFrame(coords)\n",
    "    pca_df.columns = [f\"PC{pc+1}\" for pc in range(n_components)]\n",
    "    pca_df = pd.concat([metadata, pca_df], axis=1)\n",
    "    \n",
    "    return pca_df, model\n",
    "\n",
    "def plot_pca(pca_df, colour_column, cohort_columns, dataset, n_components=6, height=500, width=750):\n",
    "    fig1 = px.scatter(\n",
    "        pca_df, \n",
    "        x='PC1', \n",
    "        y='PC2', \n",
    "        title=f\"PCA {dataset} | PC1 vs PC2 | coloured by {colour_column}\", \n",
    "        color=colour_column, \n",
    "        hover_data=cohort_columns, \n",
    "        template='simple_white',\n",
    "        height=height,\n",
    "        width=width\n",
    "    )\n",
    "    \n",
    "    if n_components < 4:\n",
    "        return fig1, None\n",
    "\n",
    "    fig2 = px.scatter(\n",
    "        pca_df, \n",
    "        x='PC3', \n",
    "        y='PC4', \n",
    "        title=f\"PCA {dataset} | PC3 vs PC4 | coloured by {colour_column}\", \n",
    "        color=colour_column, \n",
    "        hover_data=cohort_columns,\n",
    "        template='simple_white',\n",
    "        height=height,\n",
    "        width=width,\n",
    "    )\n",
    "    return fig1, fig2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6302ed5",
   "metadata": {
    "tags": [
     "parameters",
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = 'ag-vampir-002'\n",
    "vcf_path = f\"../../results/vcfs/amplicons/{dataset}.annot.vcf\"\n",
    "metadata_path = \"../../results/config/metadata.qcpass.tsv\"\n",
    "cohort_cols = 'taxon,location'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696938a0",
   "metadata": {},
   "source": [
    "## Population structure\n",
    "\n",
    "In this notebook, we run a principal components analysis and build a neighbour joining tree on the amplicon sequencing variant data. For the PCA, we will plot PC1 v PC2 and PC3 v PC4, and the variance explained by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae6392",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "cohort_cols = cohort_cols.split(\",\")\n",
    "\n",
    "if metadata_path.endswith('.xlsx'):\n",
    "    metadata = pd.read_excel(metadata_path, engine='openpyxl')\n",
    "elif metadata_path.endswith('.tsv'):\n",
    "    metadata = pd.read_csv(metadata_path, sep=\"\\t\")\n",
    "elif metadata_path.endswith('.csv'):\n",
    "    metadata = pd.read_csv(metadata_path, sep=\",\")\n",
    "else:\n",
    "    raise ValueError(\"Metadata file must be .xlsx or .csv\")\n",
    "\n",
    "df_pca, model = pca(metadata, vcf_path, n_components=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b018edf",
   "metadata": {},
   "source": [
    "#### Variance explained\n",
    "\n",
    "As a general rule of thumb, when the variance explained for each PC begins to flatten out, that is when the PCs are no longer informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a0d44",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig = px.bar(model.explained_variance_ratio_ , labels={\n",
    "                     \"value\": \"Variance Explained\",\n",
    "                     \"index\": \"Principal Component\",\n",
    "                 }, template='simple_white', height=250, width=600)\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b98cf",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0e807c",
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "for coh in cohort_cols:\n",
    "    fig1, fig2 = plot_pca(df_pca, colour_column=coh, cohort_columns=cohort_cols, dataset=dataset, n_components=4)\n",
    "    fig1.show()\n",
    "    fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bbe3f6",
   "metadata": {},
   "source": [
    "## NJT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e53849e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "from scipy.spatial.distance import squareform  # type: ignore\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def multiallelic_diplotype_pdist(X, metric):\n",
    "    \"\"\"Optimised implementation of pairwise distance between diplotypes.\n",
    "\n",
    "    N.B., here we assume the array X provides diplotypes as genotype allele\n",
    "    counts, with axes in the order (n_samples, n_sites, n_alleles).\n",
    "\n",
    "    Computation will be faster if X is a contiguous (C order) array.\n",
    "\n",
    "    The metric argument is the function to compute distance for a pair of\n",
    "    diplotypes. This can be a numba jitted function.\n",
    "\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    n_pairs = (n_samples * (n_samples - 1)) // 2\n",
    "    out = np.zeros(n_pairs, dtype=np.float32)\n",
    "\n",
    "    # Loop over samples, first in pair.\n",
    "    for i in range(n_samples):\n",
    "        x = X[i, :, :]\n",
    "\n",
    "        # Loop over observations again, second in pair.\n",
    "        for j in numba.prange(i + 1, n_samples):\n",
    "            y = X[j, :, :]\n",
    "\n",
    "            # Compute distance for the current pair.\n",
    "            d = metric(x, y)\n",
    "\n",
    "            # Store result for the current pair.\n",
    "            k = square_to_condensed(i, j, n_samples)\n",
    "            out[k] = d\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def square_to_condensed(i, j, n):\n",
    "    \"\"\"Convert distance matrix coordinates from square form (i, j) to condensed form.\"\"\"\n",
    "\n",
    "    assert i != j, \"no diagonal elements in condensed matrix\"\n",
    "    if i < j:\n",
    "        i, j = j, i\n",
    "    return n * j - j * (j + 1) // 2 + i - 1 - j\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def multiallelic_diplotype_mean_cityblock(x, y):\n",
    "    \"\"\"Compute the mean cityblock distance between two diplotypes x and y. The\n",
    "    diplotype vectors are expected as genotype allele counts, i.e., x and y\n",
    "    should have the same shape (n_sites, n_alleles).\n",
    "\n",
    "    N.B., here we compute the mean value of the distance over sites where\n",
    "    both individuals have a called genotype. This avoids computing distance\n",
    "    at missing sites.\n",
    "\n",
    "    \"\"\"\n",
    "    n_sites = x.shape[0]\n",
    "    n_alleles = x.shape[1]\n",
    "    distance = np.float32(0)\n",
    "    n_sites_called = np.float32(0)\n",
    "\n",
    "    # Loop over sites.\n",
    "    for i in range(n_sites):\n",
    "        x_is_called = False\n",
    "        y_is_called = False\n",
    "        d = np.float32(0)\n",
    "\n",
    "        # Loop over alleles.\n",
    "        for j in range(n_alleles):\n",
    "            # Access allele counts.\n",
    "            xc = np.float32(x[i, j])\n",
    "            yc = np.float32(y[i, j])\n",
    "\n",
    "            # Check if any alleles observed.\n",
    "            x_is_called = x_is_called or (xc > 0)\n",
    "            y_is_called = y_is_called or (yc > 0)\n",
    "\n",
    "            # Compute cityblock distance (absolute difference).\n",
    "            d += np.fabs(xc - yc)\n",
    "\n",
    "        # Accumulate distance for the current pair, but only if both samples\n",
    "        # have a called genotype.\n",
    "        if x_is_called and y_is_called:\n",
    "            distance += d\n",
    "            n_sites_called += np.float32(1)\n",
    "\n",
    "    # Compute the mean distance over sites with called genotypes.\n",
    "    if n_sites_called > 0:\n",
    "        mean_distance = distance / n_sites_called\n",
    "    else:\n",
    "        mean_distance = np.nan\n",
    "\n",
    "    return mean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0977f1",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "vcf_path = f\"results/vcfs/amplicons/{dataset}.annot.vcf\"\n",
    "geno, pos, contig, df_samples = load_vcf(vcf_path, metadata=metadata)\n",
    "\n",
    "import anjl\n",
    "\n",
    "ac = allel.GenotypeArray(geno).to_allele_counts(max_allele=3)\n",
    "X = np.ascontiguousarray(np.swapaxes(ac.values, 0, 1))\n",
    "\n",
    "dists = multiallelic_diplotype_pdist(X, metric=multiallelic_diplotype_mean_cityblock)\n",
    "dists = squareform(dists)\n",
    "df_samples = df_samples.set_index('sample_id')\n",
    "df = df_samples[['taxon', 'location']]\n",
    "\n",
    "df_dist_matrix = pd.DataFrame(dists, index=df_samples.index.to_list(), columns=df_samples.index.to_list())\n",
    "# pivot long \n",
    "df_dists = df_dist_matrix.stack().reset_index().set_axis('sample_id_x sample_id_y distance'.split(), axis=1)\n",
    "# merge with metadata\n",
    "df_dists = df_dists.merge(df, left_on='sample_id_x', right_index=True).merge(df, left_on='sample_id_y', right_index=True, suffixes=('_x', '_y'))\n",
    "# remove self comparisons\n",
    "df_dists = df_dists[df_dists['sample_id_x'] != df_dists['sample_id_y']]\n",
    "# dedup\n",
    "df_dists = df_dists.assign(dedup=np.array([''.join(sorted([a,b])) for a,b in zip(df_dists.sample_id_x, df_dists.sample_id_y)]).astype(str))\n",
    "df_dists = df_dists.sort_values('sample_id_x').drop_duplicates('dedup').drop('dedup', axis=1)\n",
    "# normalise distances\n",
    "df_dists = df_dists.assign(location=lambda x: x.location_x + \" | \" + x.location_y).drop(['location_x', 'location_y'], axis=1)\n",
    "df_grp_dists = df_dists.groupby('location').agg({'distance': 'mean'}).sort_values('distance').rename(columns={'distance': 'mean_distance'}).reset_index()\n",
    "df_dists = df_dists.merge(df_grp_dists, on='location').assign(normalised_dist=lambda x: x.distance - x.mean_distance).sort_values('normalised_dist')\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# get the 500 most distant samples and exclude highly irregular ones \n",
    "far_samples = df_dists.sort_values('normalised_dist', ascending=False)[:int(df_dists.shape[0] * 0.005)][['sample_id_x', 'sample_id_y']].values.flatten()\n",
    "far_samples, far_counts = np.unique(far_samples, return_counts=True)\n",
    "exclude_outliers = far_samples[far_counts > int(df_dists.shape[0] * 0.0005)]\n",
    "print(f\"excluding extreme outliers from NJT\", exclude_outliers)\n",
    "\n",
    "dists = df_dist_matrix.drop(exclude_outliers, axis=0).drop(exclude_outliers, axis=1).values\n",
    "leaf_data = df_samples.query(\"sample_id not in @exclude_outliers\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d50cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = anjl.dynamic_nj(dists)\n",
    "\n",
    "fig = anjl.plot(\n",
    "    Z,\n",
    "    leaf_data=leaf_data,\n",
    "    color=\"location\",\n",
    "    hover_name=\"sample_id\",\n",
    "    hover_data=cohort_cols,\n",
    "    marker_size=8\n",
    ")\n",
    "fig.write_image(\"../../njt.png\", scale=2)\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
